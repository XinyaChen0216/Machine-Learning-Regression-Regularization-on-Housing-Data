{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 52772\n",
      "Classes: ['malignant' 'benign']\n",
      "Standard scaling will not change y, so class balance stays the same before and after standardization.\n",
      "Train: n=341\n",
      "class Malignant(0): 127 (37.2%)\n",
      "class Benign(1): 214 (62.8%)\n",
      "Val: n=114\n",
      "class Malignant(0): 43 (37.7%)\n",
      "class Benign(1): 71 (62.3%)\n",
      "Test: n=114\n",
      "class Malignant(0): 42 (36.8%)\n",
      "class Benign(1): 72 (63.2%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 Task 2: Classification — Probabilistic & Linear Models\n",
    "# Dataset: Breast Cancer Wisconsin (Diagnostic).\n",
    "# Goal: Implement GNB, GDA (shared and class-specific covariance), Logistic Regression via\n",
    "# gradient descent, and Perceptron (or averaged perceptron) from scratch.\n",
    "\n",
    "# 2.1 2A. Data Preprocessing (Required)\n",
    "# 1. Use your seed to create a 60/20/20 train/validation/test split.\n",
    "# 2. Standardize features (justify if you choose otherwise).\n",
    "# 3. Report class balance and at least one visualization.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"seed.txt\", \"r\") as f:\n",
    "    seed = int(f.read().strip())\n",
    "\n",
    "print(f\"seed = {seed}\")\n",
    "\n",
    "#Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data.astype(float)          \n",
    "y = data.target.astype(int)          \n",
    "feature_names = data.feature_names\n",
    "target_names = data.target_names  \n",
    "\n",
    "print(f\"Classes: {target_names}\")\n",
    "\n",
    "#60/20/20 split with stratification\n",
    "X_train_raw, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=seed, stratify=y\n",
    ")\n",
    "X_val_raw, X_test_raw, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=seed, stratify=y_temp\n",
    ")\n",
    "\n",
    "#Standardize using TRAIN statistics only\n",
    "mu = X_train_raw.mean(axis=0)\n",
    "sigma = X_train_raw.std(axis=0, ddof=0)\n",
    "sigma[sigma == 0] = 1.0  #prevents division by zero\n",
    "\n",
    "X_train = (X_train_raw - mu) / sigma\n",
    "X_val   = (X_val_raw   - mu) / sigma\n",
    "X_test  = (X_test_raw  - mu) / sigma\n",
    "\n",
    "#Class balance reporting helper\n",
    "def report_balance(name, y_split):\n",
    "    n = len(y_split)\n",
    "    \n",
    "    #count how many samples belong to each class; binary classification 0 or 1\n",
    "    counts = np.bincount(y_split, minlength=2) \n",
    "\n",
    "    #convert count to percentage\n",
    "    percentage = counts / n * 100 \n",
    "\n",
    "    print(f\"{name}: n={n}\")\n",
    "    print(f\"class Malignant(0): {counts[0]} ({percentage[0]:.1f}%)\")\n",
    "    print(f\"class Benign(1): {counts[1]} ({percentage[1]:.1f}%)\")\n",
    "\n",
    "\n",
    "print(\"Standard scaling will not change y, so class balance stays the same before and after standardization.\")\n",
    "report_balance(\"Train\", y_train)\n",
    "report_balance(\"Val\", y_val)\n",
    "report_balance(\"Test\", y_test)\n",
    "\n",
    "# Visualization\n",
    "splits = [\"Train\", \"Val\", \"Test\"]\n",
    "counts0 = [np.sum(y_train == 0), np.sum(y_val == 0), np.sum(y_test == 0)]\n",
    "counts1 = [np.sum(y_train == 1), np.sum(y_val == 1), np.sum(y_test == 1)]\n",
    "\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x - width/2, counts0, width, label=\"class Malignant(0)\")\n",
    "plt.bar(x + width/2, counts1, width, label=\"class Benign(1)\")\n",
    "plt.xticks(x, splits)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 2C. Implementations (From Scratch)\n",
    "# 1. Gaussian Naive Bayes (log-probabilities required)\n",
    "class GaussianNaiveBayes:\n",
    "    #prior: probability of each class before seeing any features\n",
    "    \"\"\"logP(y=c|x)∝logP(y=c)+logP(x|y=c)\"\"\"\n",
    "    \"\"\"logP(y=c) -> prior\"\"\"\n",
    "    \"\"\"logP(x|y=c) -> log_likelihood() implemented below\"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.priors = {}\n",
    "        self.means = {}\n",
    "        self.varians = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n = len(y) \n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.priors[c] = len(X_c) / n\n",
    "            self.means[c] = X_c.mean(axis=0)\n",
    "            self.varians[c] = X_c.var(axis=0) + 1e-9 #numerical smoothing\n",
    "        return self\n",
    "    \n",
    "    def log_likelihood(self, X, c):\n",
    "        mean = self.means[c]\n",
    "        varian = self.varians[c]\n",
    "        # computer log P(x | class=c)\n",
    "        log_prob = -0.5 * (np.log(2 * np.pi * varian) + (X -  mean)**2 / varian)\n",
    "        return log_prob.sum(axis=1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_posteriors = []\n",
    "        for c in self.classes:\n",
    "            log_prior = np.log(self.priors[c])\n",
    "            log_ll = self.log_likelihood(X, c)\n",
    "            log_posteriors.append(log_prior + log_ll)\n",
    "        log_posteriors = np.array(log_posteriors)\n",
    "        return self.classes[np.argmax(log_posteriors,axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GDA with shared covariance and class-specific covariance\n",
    "class GDA:\n",
    "    def __init__(self, shared_covariance=True):\n",
    "        self.shared_covariance = shared_covariance\n",
    "        self.classes = None\n",
    "        self.priors = {}\n",
    "        self.means = {}\n",
    "        self.covs = {}\n",
    "        self.shared_cov_matrix = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n, d = X.shape\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.priors[c] = len(X_c) / n\n",
    "            self.means[c] = X_c.mean(axis=0)\n",
    "            self.covs[c] = np.cov(X_c, rowvar=False) + 1e-6 * np.eye(d) # add a tiny value to the diagonal\n",
    "\n",
    "        if self.shared_covariance:\n",
    "            self.shared_cov_matrix = np.zeros((d, d))\n",
    "            for c in self.classes:\n",
    "                n_c = np.sum(y == c)\n",
    "                self.shared_cov_matrix += (n_c - 1) * self.covs[c]\n",
    "            self.shared_cov_matrix /= (n - len(self.classes))\n",
    "            self.shared_cov_matrix += 1e-6 * np.eye(d)\n",
    "        return self\n",
    "\n",
    "    #look up chatGPT: \"multivariate Guassian Log-Density\"\n",
    "    def _log_likelihood(self, X, c):\n",
    "        mean = self.means[c]\n",
    "        cov = self.shared_cov_matrix if self.shared_covariance else self.covs[c]\n",
    "        d = X.shape[1]\n",
    "        diff = X - mean\n",
    "        # mutilvariate Gaussian Log-Density\n",
    "        # log N(x; mu, Sigma) = -0.5 * [d*log(2*pi) + log|Sigma| + (x-mu)^T Sigma^{-1} (x-mu)]\n",
    "        sign, logdet = np.linalg.slogdet(cov) #log|sigma|\n",
    "        cov_inv = np.linalg.inv(cov) \n",
    "        mahal = np.sum(diff @ cov_inv * diff, axis=1) #(x-mu)^T Sigma^{-1} (x-mu)\n",
    "        return -0.5 * (d * np.log(2 * np.pi) + logdet + mahal)\n",
    "\n",
    "    def predict(self, X):\n",
    "        log_posteriors = []\n",
    "        for c in self.classes:\n",
    "            log_prior = np.log(self.priors[c])\n",
    "            log_ll = self._log_likelihood(X, c)\n",
    "            log_posteriors.append(log_prior + log_ll)\n",
    "        log_posteriors = np.array(log_posteriors)\n",
    "        return self.classes[np.argmax(log_posteriors, axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logistic Regression using batch gradient descent (with optional L2)\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.1, epochs=2000, l2=0.0, tol=1e-7):\n",
    "        \"\"\"\n",
    "        lr: learning rate\n",
    "        epochs: max iterations\n",
    "        l2: L2 strength (lambda). 0.0 means no regularization.\n",
    "        tol: stop if parameter change is tiny\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.l2 = l2\n",
    "        self.tol = tol\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "        \n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def cost(self, h, y):\n",
    "        \"\"\"Binary cross-entropy loss: Jdata = -m1​∑[ylog(h)+(1-y)log(1-h)]\"\"\"\n",
    "        \"\"\"J = J(data) + J(reg)\"\"\"\n",
    "        m = len(y)\n",
    "        eps = 1e-12\n",
    "        h = np.clip(h, eps, 1 - eps) # prevent log(0)\n",
    "\n",
    "        binary_cross_entropy = - (1/m) * np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "        reg = (self.lam / (2*m)) * np.sum(self.theta[1:]**2) #[1:] -> intercept not regularized\n",
    "        \n",
    "        return binary_cross_entropy + reg\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train model using gradient descent\"\"\"\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            z = np.dot(X, self.weights) + self.bias\n",
    "            h = self.sigmoid(z)\n",
    "\n",
    "            dw = (1/m) * np.dot(X.T, (h - y))\n",
    "            db = (1/m) * np.sum(h - y)\n",
    "\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.sigmoid(np.dot(X, self.weights) + self.bias) >= 0.5).astype(int)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Perceptron (or averaged perceptron)\n",
    "class Perceptron:\n",
    "    # lr: learning rate\n",
    "    # epochs: the number of times the algorithms goes through during learning \n",
    "    # w: weights\n",
    "    # b: bias\n",
    "    def __init__(self, lr=0.1, epochs=1000, fit_intercept=True, convergence_tolerance = 1e-6):\n",
    "        self.lr =  lr\n",
    "        self.epochs = epochs\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.w = None\n",
    "        self.b = 0.0\n",
    "        self.n_features = None\n",
    "        self.convergence_tolerance = convergence_tolerance\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n, p = X.shape\n",
    "        #initilization\n",
    "        self.n_features = p\n",
    "        self.w = np.zeros(p)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            #save for convergence checking\n",
    "            w_old = self.w.copy()\n",
    "            b_old = self.b\n",
    "\n",
    "            for i in range(n):\n",
    "                xi = X[i]\n",
    "                yi = y[i]\n",
    "\n",
    "                score = xi @ self.w + (self.b if self.fit_intercept else 0.0)\n",
    "                y_pred = 1 if score >=0 else -1\n",
    "\n",
    "                # learning - update w and b if misclassify\n",
    "                if y_pred != yi:\n",
    "                    self.w += self.lr * yi * xi\n",
    "                    if self.fit_intercept:\n",
    "                        self.b += self.lr * yi\n",
    "            w_change = np.linalg.norm(self.w - w_old)\n",
    "            b_change = abs(self.b -b_old) if self.fit_intercept else 0.0\n",
    "\n",
    "            if w_change < self.convergence_tolerance and b_change <self.convergence_tolerance:\n",
    "                #print(f\"Converged!\")\n",
    "                break\n",
    "\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        scores = X @ self.w + (self.b if self.fit_intercept else 0.0)\n",
    "        return (scores >=0).astype(int)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on test set:\n",
    "# • Accuracy, Precision, Recall, F1\n",
    "# • Confusion matrix\n",
    "def metrics(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    #construct confusion matrix\n",
    "    cm = np.array([[tp,fn],[fp,tn]])\n",
    "    # print(f\"True positive: {tp}, False positive: {fp}, True negative: {tn}, False negative: {fn}\")\n",
    "    # print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "    # print(f\"Confusion Matrix: {cm}\")\n",
    "\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall,\n",
    "            'f1': f1, \"confusion\": cm}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                       Accuracy  Precision     Recall         F1\n",
      "---------------------------------------------------------------------\n",
      "GNB                           0.1140     0.2264     0.1667     0.1920\n",
      "GDA (Shared)                  0.9298     0.9000     1.0000     0.9474\n",
      "GDA (Class-specific)          0.9649     0.9722     0.9722     0.9722\n",
      "Logistic Regression           0.9737     0.9726     0.9861     0.9793\n",
      "Perceptron                    0.6316     0.6316     1.0000     0.7742\n"
     ]
    }
   ],
   "source": [
    "# fit models\n",
    "\n",
    "gnb = GaussianNaiveBayes().fit(X_train, y_train)\n",
    "gda_shared = GDA(shared_covariance=True).fit(X_train, y_train)\n",
    "gda_specific = GDA(shared_covariance=False).fit(X_train, y_train)\n",
    "log_reg = LogisticRegression(lr=0.1, epochs=1000).fit(X_train, y_train)\n",
    "perceptron = Perceptron(lr=0.1, epochs=1000).fit(X_train, y_train)\n",
    "\n",
    "def evaluate_models(y_true, model_preds):\n",
    "    results = {}\n",
    "\n",
    "    header = f\"{'Model':<25} {'Accuracy':>10} {'Precision':>10} {'Recall':>10} {'F1':>10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    for name, y_pred in model_preds.items():\n",
    "        m = metrics(y_true, y_pred)\n",
    "        results[name] = m\n",
    "\n",
    "        print(f\"{name:<25} \"\n",
    "              f\"{m['accuracy']:>10.4f} \"\n",
    "              f\"{m['precision']:>10.4f} \"\n",
    "              f\"{m['recall']:>10.4f} \"\n",
    "              f\"{m['f1']:>10.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "model_predictions = {\n",
    "    \"GNB\": gnb.predict(X_test),\n",
    "    \"GDA (Shared)\": gda_shared.predict(X_test),\n",
    "    \"GDA (Class-specific)\": gda_specific.predict(X_test),\n",
    "    \"Logistic Regression\": log_reg.predict(X_test),\n",
    "    \"Perceptron\": perceptron.predict(X_test),\n",
    "}\n",
    "all_metrics = evaluate_models(y_test, model_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
